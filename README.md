# ğŸ“¦ Demand Forecasting for Multiple Products

Predicting demand accurately is crucial for optimizing inventory, supply chain operations, and minimizing costs. In this project, I built and compared multiple regression models to forecast product demand across various warehouses using real-world retail sales data.

---

## ğŸ§  Problem Overview

Retailers with large catalogs need accurate demand predictions to:
- Avoid **overstocking** (which ties up capital)
- Prevent **stockouts** (which cost sales and hurt customer trust)
- Improve **logistics** and **warehouse planning**

We tackle this by building a demand forecasting pipeline that uses historical sales data to predict **future product demand** across **multiple warehouses**.

---

## ğŸ“ Dataset

- **Total Records:** 22,857
- **Target:** Demand quantity for a given `Product_ID` at a specific `Warehouse_ID`
- **Features include:**
  - Product ID
  - Warehouse ID
  - Historical demand
  - Date
  - Lag features & rolling averages for previous demand behavior

---

## âš™ï¸ Models Used

We evaluated three popular models:
1. **Linear Regression** â€“ Fast and interpretable
2. **Random Forest Regressor** â€“ Non-linear ensemble model
3. **XGBoost Regressor** â€“ Gradient boosting, great for tabular data

Each model was trained on the same feature-engineered dataset and evaluated using:
- **MAE (Mean Absolute Error)** â€“ measures average magnitude of error
- **RMSE (Root Mean Squared Error)** â€“ penalizes large errors more heavily

---

## ğŸ“Š Model Performance

Hereâ€™s how the models performed on the test set:

![Model Comparison](outputs/model_comparison.png)

> âœ… **XGBoost outperformed the others**, achieving the **lowest RMSE** and capturing non-linear trends in product demand.

| Model              | MAE     | RMSE    |
|-------------------|---------|---------|
| Linear Regression | 37.10   | 46.83   |
| Random Forest     | 26.32   | 34.91   |
| **XGBoost**       | **23.84** | **31.16** |

- XGBoost improved RMSE by **33.5%** compared to Linear Regression  
- Random Forest also outperformed Linear Regression by **25.5%**

---

## ğŸ“ˆ Forecast vs Actual

To evaluate visually, we plotted predicted demand vs actual demand for a sample productâ€“warehouse pair:

![Forecast vs Actual](outputs/forecasts.png)

- The XGBoost model closely follows actual demand patterns over time
- Occasional spikes were captured well, showing good responsiveness to short-term trends

---

## ğŸ” SHAP Explainability

To interpret what features the XGBoost model relied on most, we used **SHAP (SHapley Additive exPlanations)**:

![SHAP Summary](outputs/shap_feature_importance.png)

- **Lag-based features** (previous demand values) were the most influential
- **Rolling averages** helped smooth out demand noise
- Categorical encodings of `Product_ID` and `Warehouse_ID` contributed to location-specific trends

This gave us deep insight into **how demand evolves over time** and how recent history impacts forecasts.

---

## ğŸ› ï¸ Technical Stack

- `Python`, `Pandas`, `NumPy`, `Matplotlib`, `Seaborn`
- `Scikit-learn` for model evaluation
- `XGBoost` for high-performance regression
- `SHAP` for model explainability
- `Jupyter Notebook` for development and visualization

---

## ğŸ“Œ Key Takeaways

- Forecasting demand across products and locations requires capturing **temporal** and **categorical** signals.
- Ensemble models like XGBoost drastically outperform linear models when tuned correctly.
- Explainability tools like SHAP are essential for making ML models **trustworthy** in supply chain decisions.
- This pipeline can be adapted to any business that tracks historical demand â€” from **retail**, **e-commerce**, to **warehouse logistics**.

---

## ğŸ“‚ Project Structure

```
demand-forecasting/
â”œâ”€â”€ data/
â”‚   â””â”€â”€ demand.csv
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ model_comparison.png
â”‚   â”œâ”€â”€ forecast_vs_actual.png
â”‚   â””â”€â”€ shap_summary.png
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ demand_forecasting.ipynb
â”œâ”€â”€ src/
â”‚   â””â”€â”€ feature_engineering.py
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt
```

---

## ğŸš€ Next Steps

- Implement time series-specific models (e.g., LSTM, Prophet) for comparison
- Use hyperparameter tuning (GridSearchCV / Optuna) for further performance boosts
- Extend pipeline to **real-time prediction** for live inventory systems

---

## ğŸ™Œ About Me

I'm a software engineer and aspiring data scientist with a focus on machine learning, explainability, and applied AI. My portfolio combines both engineering and modeling projects designed to solve real-world problems at scale.  
ğŸ”— [GitHub](https://github.com/lexusimni)
[Linkedin](https://www.linkedin.com/in/alexus-glass-248061237/)

---
